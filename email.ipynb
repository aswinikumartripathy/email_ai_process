{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fb17524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9193d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import PromptHelper\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import GPTVectorStoreIndex\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.response_synthesizers import TreeSummarize\n",
    "from llama_index.core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f950294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d65c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load environment variables\n",
    "def load_api_key():\n",
    "    load_dotenv()\n",
    "    openai.api_key= os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c54406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Set global LlamaIndex settings\n",
    "def configure_llama_index():\n",
    "    Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "    Settings.embed_model = OpenAIEmbedding()\n",
    "    Settings.chunk_size_limit = 128\n",
    "    Settings.chunk_overlap = 50\n",
    "    Settings.num_output = 2048\n",
    "    prompt_helper = PromptHelper(\n",
    "        context_window = 4096,\n",
    "        num_output = 3000,\n",
    "        chunk_overlap_ratio = 0.1,\n",
    "        chunk_size_limit = 512,\n",
    "    )\n",
    "    Settings.prompt_helper = prompt_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee8ac770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create index using GPTVectorStoreIndex (which supports chunk retrieval)\n",
    "def build_vector_index(email_text: str) -> GPTVectorStoreIndex:\n",
    "    document  = Document(text=email_text)\n",
    "    index = GPTVectorStoreIndex.from_documents([document])\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f22ec65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize emails into different categories\n",
    "def categorize_email(email_text: str) -> str:\n",
    "    # Build the vector index (make sure this function is defined elsewhere)\n",
    "    index = build_vector_index(email_text)\n",
    "\n",
    "    categories = [\"payment\", \"billing\", \"enrollment\", \"uncategorized\"]\n",
    "    category_query = f\"\"\"\n",
    "    Based on the relevant parts of this email, categorize it into one of the following categories:\n",
    "    {', '.join(categories)}. If it does not fit any of these categories, please categorize it as 'uncategorized'.\n",
    "    Respond only with the category name.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve relevant chunks from the index\n",
    "    retriever = VectorIndexRetriever(index=index, similarity_top_k=3)\n",
    "    nodes = retriever.retrieve(category_query)\n",
    "\n",
    "    # Get total number of chunks\n",
    "    total_chunks = len(index.docstore.docs)\n",
    "    # print(f\"Total chunks in the index: {total_chunks}\")\n",
    "    # print(f\"Top {len(nodes)} relevant chunks retrieved:\\n\")\n",
    "\n",
    "    # for i, node in enumerate(nodes, 1):\n",
    "    #     print(f\"Chunk {i}:\\n{'-'*40}\\n{node.text.strip()}\\n\")\n",
    "\n",
    "    # Combine retrieved chunks\n",
    "    combined_text = \"\\n\".join([node.text for node in nodes])\n",
    "\n",
    "    # prompts for LLM\n",
    "    full_prompt = f\"\"\"\n",
    "    {combined_text}\n",
    "\n",
    "    Categorize this email based on the above content into one of: {', '.join(categories)}.\n",
    "\n",
    "    ---\n",
    "    1. Enrollment  \n",
    "    Categorize the email as Enrollment if any of the below keywords are found:  \n",
    "    a) AWD  \n",
    "    b) Enrollment  \n",
    "    c) Autopay  \n",
    "\n",
    "    2. Payment  \n",
    "    Categorize the email as Payment if any of the below keywords are found:  \n",
    "    a) Payment  \n",
    "    b) Cheque  \n",
    "    c) Remittance  \n",
    "    d) Invoice  \n",
    "    e) Coupon  \n",
    "    f) Credit  \n",
    "    g) Refund  \n",
    "\n",
    "    3. Billing  \n",
    "    Categorize the email as Billing if any of the below keywords are found:  \n",
    "    a) Billing  \n",
    "    b) Premium  \n",
    "    c) Invoice  \n",
    "    d) Incorrect Invoice  \n",
    "\n",
    "    Post-Processing Steps:\n",
    "\n",
    "    1. Autonomic Analysis Protocol  \n",
    "    - Automatically identify patterns and context beyond just keywords (e.g., \"I was charged wrongly\" implies billing).  \n",
    "    - Detect sentence structure and tone to infer category when explicit keywords are missing.\n",
    "\n",
    "    2. Primary Intent Detection  \n",
    "    - If multiple categories are detected, determine which intent is dominant based on keyword frequency, placement, and context.  \n",
    "    - Prioritize the category mentioned in the subject or first few lines.\n",
    "\n",
    "    3. Contradicting Evidence Check  \n",
    "    - Look for conflicting phrases (e.g., “Refund not received” implies Payment, not Billing).  \n",
    "    - Remove false positives caused by ambiguous keyword overlap (e.g., “Autopay invoice” likely relates to Enrollment, not Billing).\n",
    "\n",
    "    4. Priority Rules  \n",
    "    - If both Enrollment and Payment are detected, prioritize Enrollment.  \n",
    "    - If both Billing and Payment are detected, prioritize Payment.  \n",
    "    - If all three are mentioned, prioritize based on order: Enrollment > Payment > Billing.\n",
    "\n",
    "    5. Confidence Assessment  \n",
    "    - Assign a confidence score (0–100%) based on keyword density and clarity.  \n",
    "    - If confidence is below 60%, flag the result for manual review.\n",
    "\n",
    "    6. Integration of Atomic Signal  \n",
    "    - Include other metadata if available (e.g., subject line, tags, sender type) to refine prediction.  \n",
    "    - Example: If the sender is a known billing department, weight Billing higher.\n",
    "\n",
    "    7. Output Validation  \n",
    "    - Ensure the final category logically matches the context.  \n",
    "    - If mismatch found, re-apply rules from step 1 to 6.  \n",
    "    - Log output decision along with justification for traceability.\n",
    "\n",
    "    If none of the keywords match, categorize the email as 'uncategorized'.\n",
    "    Respond with only 1 word from the following : **payment**, **billing**, **enrollment**, **uncategorized**.\n",
    "    \"\"\"\n",
    "\n",
    "    response = Settings.llm.complete(full_prompt)\n",
    "    return response.text.strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b0589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_chunks(index: GPTVectorStoreIndex):\n",
    "    # return list of node object already used in the index\n",
    "    return list(index.docstore.docs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa45cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_summerize(index: GPTVectorStoreIndex, summary_window_words: int = 100) -> str:\n",
    "    nodes = get_existing_chunks(index)\n",
    "\n",
    "    summary_template = PromptTemplate(\n",
    "        f\"Summerize the following text into approximately {summary_window_words} words:\\n\\n\"\n",
    "        \"{{context_str}}\\n\\nSummary:\"\n",
    "    )\n",
    "\n",
    "    tree_summerizer = TreeSummarize(summary_template=summary_template)\n",
    "    summary_index = DocumentSummaryIndex(nodes)\n",
    "\n",
    "    query_engine = summary_index.as_query_engine(response_synthesizer=tree_summerizer)\n",
    "    response = query_engine.query(\"Please summerize the entire content of this email.\")\n",
    "\n",
    "    return response.response.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08956632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_email_from_file(file_path: str) -> str:\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        email_text = file.read()\n",
    "    return email_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76e703f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: enrollment\n",
      "current doc id: b08ae810-2a18-4883-9e6d-f1b35831b5ba\n",
      "\n",
      "Email Summary: Your enrollment in the Premium Plan is confirmed. Your subscription is active, with autopay enabled. You will receive updates and can modify your plan anytime. For questions about your enrollment or billing, contact our support team. Thank you for choosing our services!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    load_api_key()\n",
    "    configure_llama_index()\n",
    "\n",
    "    # Load email text from a file\n",
    "    email_text = load_email_from_file(\"emails/email4.txt\")\n",
    "    index = build_vector_index(email_text)\n",
    "\n",
    "    category = categorize_email(email_text)\n",
    "    print(f\"Predicted Category: {category}\")\n",
    "\n",
    "    summary = recursive_summerize(index, summary_window_words=50)\n",
    "    print(f\"\\nEmail Summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a16dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myprojects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
